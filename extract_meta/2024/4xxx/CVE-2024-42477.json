{
  "CVE Code": "CVE-2024-42477",
  "Published": "2024-08-12T15:02:40.980Z",
  "Updated": "2024-08-13T14:07:30.334Z",
  "Description": "llama.cpp provides LLM inference in C/C++. The unsafe `type` member in the `rpc_tensor` structure can cause `global-buffer-overflow`. This vulnerability may lead to memory data leakage. The vulnerability is fixed in b3561.",
  "ProblemTypes": [
    "CWE-125: Out-of-bounds Read"
  ],
  "Affected": [
    {
      "vendor": "ggerganov",
      "product": "llama.cpp",
      "versions": [
        "< b3561"
      ]
    }
  ],
  "Reference": [
    "https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-mqp6-7pv6-fqjf",
    "https://github.com/ggerganov/llama.cpp/commit/b72942fac998672a79a1ae3c03b340f7e629980b"
  ]
}