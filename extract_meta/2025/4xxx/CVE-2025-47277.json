{
  "CVE Code": "CVE-2025-47277",
  "Published": "2025-05-20T17:32:27.034Z",
  "Updated": "2025-05-20T17:52:31.274Z",
  "Description": "vLLM, an inference and serving engine for large language models (LLMs), has an issue in versions 0.6.5 through 0.8.4 that ONLY impacts environments using the `PyNcclPipe` KV cache transfer integration with the V0 engine. No other configurations are affected. vLLM supports the use of the\u00a0`PyNcclPipe`\u00a0class to establish a peer-to-peer communication domain for data transmission between distributed nodes. The GPU-side KV-Cache transmission is implemented through the\u00a0`PyNcclCommunicator`\u00a0class, while CPU-side control message passing is handled via the\u00a0`send_obj`\u00a0and\u00a0`recv_obj`\u00a0methods on the CPU side.\u200b The intention was that this interface should only be exposed to a private network using the IP address specified by the `--kv-ip` CLI parameter. The vLLM documentation covers how this must be limited to a secured network. The default and intentional behavior from PyTorch is that the `TCPStore` interface listens on ALL interfaces, regardless of what IP address is provided. The IP address given was only used as a client-side address to use. vLLM was fixed to use a workaround to force the `TCPStore` instance to bind its socket to a specified private interface. As of version 0.8.5, vLLM limits the `TCPStore` socket to the private interface as configured.",
  "ProblemTypes": [
    "CWE-502: Deserialization of Untrusted Data"
  ],
  "Affected": [
    {
      "vendor": "vllm-project",
      "product": "vllm",
      "versions": [
        ">= 0.6.5, < 0.8.5"
      ]
    }
  ],
  "Reference": [
    "https://github.com/vllm-project/vllm/security/advisories/GHSA-hjq4-87xh-g4fv",
    "https://github.com/vllm-project/vllm/pull/15988",
    "https://github.com/vllm-project/vllm/commit/0d6e187e88874c39cda7409cf673f9e6546893e7",
    "https://docs.vllm.ai/en/latest/deployment/security.html"
  ]
}