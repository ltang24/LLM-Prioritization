{
  "CVE Code": "CVE-2025-53630",
  "Published": "2025-07-10T19:32:45.296Z",
  "Updated": "2025-07-10T20:31:07.240Z",
  "Description": "llama.cpp is an inference of several LLM models in C/C++. Integer Overflow in the gguf_init_from_file_impl function in ggml/src/gguf.cpp can lead to Heap Out-of-Bounds Read/Write. This vulnerability is fixed in commit 26a48ad699d50b6268900062661bd22f3e792579.",
  "ProblemTypes": [
    "CWE-122: Heap-based Buffer Overflow",
    "CWE-680: Integer Overflow to Buffer Overflow"
  ],
  "Affected": [
    {
      "vendor": "ggml-org",
      "product": "llama.cpp",
      "versions": [
        "< 26a48ad699d50b6268900062661bd22f3e792579"
      ]
    }
  ],
  "Reference": [
    "https://github.com/ggml-org/llama.cpp/security/advisories/GHSA-vgg9-87g3-85w8",
    "https://github.com/ggml-org/llama.cpp/commit/26a48ad699d50b6268900062661bd22f3e792579"
  ]
}