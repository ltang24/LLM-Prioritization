#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime

# ====== å‚æ•°é…ç½®ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰ ======
FILE_PATH = '/home/xiaoqun/RQ3_Experimants/epss_analysis/epss_history.json'

# å°†â€œç¨³å®š/è½»å¾®æ³¢åŠ¨â€åˆå¹¶ä¸ºä¸€ç±»çš„é˜ˆå€¼
STABLE_THRESHOLD = 0.001     # æç¨³å®šé˜ˆå€¼ï¼šmax-min < 0.001
MILD_THRESHOLD   = 0.01      # è½»å¾®æ³¢åŠ¨é˜ˆå€¼ï¼šèŒƒå›´ < 0.01 ä¹Ÿè§†ä¸º stable

# åˆ¤å®šâ€œçªå˜â€çš„æœ€å°è·³å˜ï¼ˆç›¸é‚»ä¸¤ç‚¹å·®å€¼é˜ˆå€¼ï¼‰ï¼Œç”¨äºè¾…åŠ©è§£é‡Š
JUMP_THRESHOLD   = 0.10

REPORT_PREFIX = "epss_trend_report"
IMG_PREFIX    = "epss_trend_analysis"
JSON_PREFIX   = "epss_trend"

# Matplotlib è®¾ç½®
plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (14, 6)


# ========= æ ¸å¿ƒå‡½æ•°ï¼šè¶‹åŠ¿åˆ†æï¼ˆ4ç±»ï¼‰ =========
def analyze_epss_changes(
    cve_data,
    stable_threshold=0.001,   # æç¨³å®šï¼šrange < 0.001
    mild_threshold=0.01,      # éå•è°ƒä½†æ€»ä½“æ³¢åŠ¨å¾ˆå°ï¼Œä¹Ÿç®— stable çš„ä¸Šé™
    jump_threshold=0.10,      # â€œçªå˜â€åˆ¤å®šï¼šä»»æ„ç›¸é‚»ä¸¤ç‚¹ç»å¯¹å·® > 0.10
    net_threshold=1e-4,       # â€œæ€»ä½“å¢/å‡â€æ‰€éœ€æœ€å°é¦–æœ«å‡€å˜åŒ–é˜ˆå€¼ï¼ˆ0.0001ï¼‰
    majority_ratio=0.60       # ä¸Šå‡/ä¸‹é™æ­¥æ•°å æ¯”é˜ˆå€¼ï¼ˆ60%ï¼‰
):
    """
    å››ç±»è¶‹åŠ¿ï¼ˆæ€»ä½“è¶‹åŠ¿åˆ¤æ³•ï¼‰ï¼š
      - 'stable'               : æç¨³å®šï¼›æˆ–éå•è°ƒä½†æ•´ä½“æ³¢åŠ¨å°ï¼ˆrange < mild_thresholdï¼‰
      - 'monotonic_increase'   : æ€»ä½“å‘ä¸Šï¼ˆé¦–æœ«å‡€å¢ > net_threshold ä¸” ä¸Šå‡æ­¥æ•°å æ¯” >= majority_ratioï¼‰
      - 'monotonic_decrease'   : æ€»ä½“å‘ä¸‹ï¼ˆé¦–æœ«å‡€å‡ < -net_threshold ä¸” ä¸‹é™æ­¥æ•°å æ¯” >= majority_ratioï¼‰
      - 'sudden_change'        : å­˜åœ¨å¤§è·³å˜ï¼Œæˆ–æ•´ä½“æ³¢åŠ¨è¾ƒå¤§ä¸”ä¸æ»¡è¶³æ€»ä½“å¢/å‡
    """
    history = cve_data.get('epss_history', [])
    if not history or len(history) < 2:
        return None

    # å–å¹¶æ’åº
    try:
        scores = [float(h['new_score']) for h in history]
        dates  = [datetime.strptime(h['date'], '%Y-%m-%d') for h in history]
        dates, scores = zip(*sorted(zip(dates, scores)))
    except Exception:
        return None

    scores = np.asarray(scores, dtype=float)
    diffs  = np.diff(scores)
    abs_diffs = np.abs(diffs)

    max_score   = float(scores.max())
    min_score   = float(scores.min())
    score_range = max_score - min_score
    max_jump    = float(abs_diffs.max()) if len(abs_diffs) else 0.0

    first_score = float(scores[0])
    last_score  = float(scores[-1])
    net_change  = last_score - first_score

    # æ­¥æ•°ç»Ÿè®¡ï¼ˆå¿½ç•¥ä¸º0çš„æ­¥ï¼‰
    pos_steps = int(np.sum(diffs > 0))
    neg_steps = int(np.sum(diffs < 0))
    eff_steps = pos_steps + neg_steps
    pos_ratio = (pos_steps / eff_steps) if eff_steps > 0 else 0.0
    neg_ratio = (neg_steps / eff_steps) if eff_steps > 0 else 0.0

    # 1) æç¨³å®šï¼ˆä¼˜å…ˆï¼‰
    if score_range < stable_threshold and max_jump < stable_threshold:
        trend = "stable"

    # 2) æ˜æ˜¾çªå˜
    elif max_jump >= jump_threshold:
        trend = "sudden_change"

    else:
        # 3) æ€»ä½“è¶‹åŠ¿ï¼ˆé¦–æœ«å‡€å˜åŒ– + æ­¥æ•°å æ¯”ï¼‰
        if net_change > net_threshold and pos_ratio >= majority_ratio:
            trend = "monotonic_increase"
        elif net_change < -net_threshold and neg_ratio >= majority_ratio:
            trend = "monotonic_decrease"
        else:
            # 4) éå•è°ƒä½†æ³¢åŠ¨å¾ˆå° -> stableï¼›å¦åˆ™ -> sudden_change
            trend = "stable" if score_range < mild_threshold else "sudden_change"

    return {
        'cve_id': cve_data.get('cve_id', ''),
        'trend': trend,
        'max_score': max_score,
        'min_score': min_score,
        'score_range': score_range,
        'max_jump': max_jump,
        'first_date': dates[0].strftime('%Y-%m-%d'),
        'last_date': dates[-1].strftime('%Y-%m-%d'),
        'first_score': first_score,
        'last_score': last_score,
        'net_change': net_change,
        'pos_steps': pos_steps,
        'neg_steps': neg_steps,
        'pos_ratio': pos_ratio,
        'neg_ratio': neg_ratio,
        'steps': int(len(scores)),
        'original_data': cve_data
    }



# ========= ä¿å­˜æŒ‰è¶‹åŠ¿åˆ†ç±»çš„ JSON =========
def save_classified_json(df, timestamp_str):
    """æŒ‰ trend(4ç±») å¯¼å‡º JSON"""
    print("\næ­£åœ¨ä¿å­˜è¶‹åŠ¿åˆ†ç±» JSON æ–‡ä»¶...")
    for trend_type in ['stable', 'monotonic_increase', 'monotonic_decrease', 'sudden_change']:
        sub = df[df['trend'] == trend_type]
        out = {row['cve_id']: row['original_data'] for _, row in sub.iterrows()}
        filename = f"{JSON_PREFIX}_{trend_type}_{timestamp_str}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(out, f, ensure_ascii=False, indent=2)
        print(f"âœ… {trend_type} -> {filename} ({len(out)} æ¡)")


# ========= å¯è§†åŒ–ï¼šå››ç±»è¶‹åŠ¿ =========
def draw_beautiful_chart(stable_count, mono_inc_count, mono_dec_count, sudden_count, total_cves):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))

    # é¥¼å›¾ï¼š4 ç±»è¶‹åŠ¿åˆ†å¸ƒ
    pattern_data = [
        ('Stable', stable_count, '#95a5a6'),
        ('â†‘ Monotonic Increase', mono_inc_count, '#2ecc71'),
        ('â†“ Monotonic Decrease', mono_dec_count, '#e74c3c'),
        ('Sudden Change', sudden_count, '#f39c12'),
    ]
    non_zero = [(l, c, col) for (l, c, col) in pattern_data if c > 0]
    if non_zero:
        labels, values, colors = zip(*non_zero)
        wedges, texts, autotexts = ax1.pie(
            values, labels=labels, autopct='%1.1f%%', startangle=90,
            colors=colors, textprops={'fontsize': 11, 'weight': 'bold'},
            explode=[0.05] * len(values)
        )
        for t in autotexts:
            t.set_color('white'); t.set_fontsize(10); t.set_weight('bold')
    else:
        ax1.text(0.5, 0.5, 'No Data Found', ha='center', va='center',
                 fontsize=14, weight='bold')
    ax1.set_title('EPSS Trend Distribution', fontsize=16, fontweight='bold', pad=20)

    # æŸ±çŠ¶å›¾ï¼šæ•°é‡
    categories = ['Stable', 'â†‘ Mono. Inc', 'â†“ Mono. Dec', 'Sudden']
    counts = [stable_count, mono_inc_count, mono_dec_count, sudden_count]
    colors = ['#95a5a6', '#2ecc71', '#e74c3c', '#f39c12']

    bars = ax2.bar(categories, counts, color=colors, edgecolor='white',
                   linewidth=2, alpha=0.85, width=0.6)
    ax2.set_ylabel('Number of CVEs', fontsize=14, fontweight='bold')
    ax2.set_title('CVE Trend Classification', fontsize=16, fontweight='bold', pad=20)
    ax2.grid(axis='y', linestyle='--', alpha=0.3); ax2.set_axisbelow(True)
    for bar, count in zip(bars, counts):
        percent = (count / total_cves * 100) if total_cves else 0
        h = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width() / 2,
                 h + max(1, total_cves * 0.02),
                 f"{count}\n({percent:.1f}%)",
                 ha='center', va='bottom', fontsize=12, fontweight='bold')
    ax2.spines['top'].set_visible(False); ax2.spines['right'].set_visible(False)
    ax2.tick_params(axis='both', which='major', labelsize=12)

    plt.tight_layout()
    nowstr = datetime.now().strftime('%Y%m%d_%H%M%S')
    fname = f"{IMG_PREFIX}_{nowstr}.png"
    plt.savefig(fname, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜åˆ°: {fname}")
    plt.show()


# ========= ä¸»æµç¨‹ =========
def main():
    print("æ­£åœ¨åˆ†æ EPSS æ•°æ®...")

    # 1) è¯»å–æ•°æ®
    try:
        with open(FILE_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… æˆåŠŸè¯»å–æ•°æ®æ–‡ä»¶ï¼ŒåŒ…å« {len(data)} ä¸ª CVE è®°å½•")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return

    # 2) åˆ†æè¶‹åŠ¿
    rows, failed = [], 0
    for cve_id, cve_data in data.items():
        res = analyze_epss_changes(cve_data)
        if res:
            rows.append(res)
        else:
            failed += 1
    if not rows:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®"); return

    df = pd.DataFrame(rows)
    print(f"âœ… æˆåŠŸåˆ†æ {len(df)} ä¸ª CVEï¼Œè·³è¿‡ {failed} ä¸ªæ— æ•ˆè®°å½•")

    # 3) ç»Ÿè®¡ 4 ç±»è¶‹åŠ¿
    trend_counts = df['trend'].value_counts().to_dict()
    stable_count   = trend_counts.get('stable', 0)
    mono_inc_count = trend_counts.get('monotonic_increase', 0)
    mono_dec_count = trend_counts.get('monotonic_decrease', 0)
    sudden_count   = trend_counts.get('sudden_change', 0)
    total_cves     = len(df)

    # 4) æ‰“å°æ±‡æ€»
    print("\nğŸ“Š è¶‹åŠ¿åˆ†ç±»ç»Ÿè®¡ï¼š")
    print(f"â€¢ Stableï¼ˆç¨³å®š/è½»å¾®æ³¢åŠ¨ï¼‰: {stable_count}")
    print(f"â€¢ Monotonic Increaseï¼ˆå•è°ƒå¢ï¼‰: {mono_inc_count}")
    print(f"â€¢ Monotonic Decreaseï¼ˆå•è°ƒå‡ï¼‰: {mono_dec_count}")
    print(f"â€¢ Sudden Changeï¼ˆçªå˜ï¼‰: {sudden_count}")

    # 5) ç”Ÿæˆæ—¶é—´æˆ³ç”¨äºæ–‡ä»¶å‘½å
    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')

    # 6) ä¿å­˜åˆ†ç±» JSON
    save_classified_json(df, timestamp_str)

    # 7) ç”Ÿæˆæ–‡å­—æŠ¥å‘Š
    now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    report_content = [
        "EPSS è¶‹åŠ¿åˆ†ææŠ¥å‘Šï¼ˆå››ç±»ï¼‰",
        f"åˆ†ææ—¶é—´: {now_str}",
        f"æ•°æ®æº: {FILE_PATH}",
        f"æ€»åˆ†æ CVE æ•°: {total_cves}",
        "",
        "ã€åˆ†ç±»å®šä¹‰é˜ˆå€¼ã€‘",
        f"- ç¨³å®š/è½»å¾®æ³¢åŠ¨: range < {MILD_THRESHOLD}ï¼ˆå…¶ä¸­æç¨³å®š: < {STABLE_THRESHOLD}ï¼‰",
        f"- çªå˜å‚è€ƒè·³å˜é˜ˆå€¼: ä»»æ„ç›¸é‚»ä¸¤ç‚¹å·® > {JUMP_THRESHOLD}",
        "",
        "ã€è¶‹åŠ¿ç»Ÿè®¡ã€‘",
        f"- Stable: {stable_count}",
        f"- Monotonic Increase: {mono_inc_count}",
        f"- Monotonic Decrease: {mono_dec_count}",
        f"- Sudden Change: {sudden_count}",
        "",
        "ã€å˜åŒ–èŒƒå›´ç»Ÿè®¡ã€‘",
        f"- æœ€å¤§å˜åŒ–: {df['score_range'].max():.4f}",
        f"- æœ€å°å˜åŒ–: {df['score_range'].min():.4f}",
        f"- å¹³å‡å˜åŒ–: {df['score_range'].mean():.4f}",
        "",
        "ï¼ˆæ³¨ï¼šå¯åœ¨è„šæœ¬é¡¶éƒ¨è°ƒæ•´é˜ˆå€¼ä»¥é€‚é…ä½ çš„æ•°æ®ç‰¹æ€§ï¼‰"
    ]
    fname = f"{REPORT_PREFIX}_{timestamp_str}.txt"
    with open(fname, 'w', encoding='utf-8') as f:
        f.write("\n".join(report_content))
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {fname}")

    # 8) ç”Ÿæˆå›¾è¡¨
    draw_beautiful_chart(
        stable_count, mono_inc_count, mono_dec_count, sudden_count, total_cves
    )


if __name__ == '__main__':
    main()
