[
  {
    "ref_link": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
    "ref_desc": "",
    "ref_summary": {
      "Attack_Vector": {
        "Attack_Vector_Reasoning": "Based on the provided information only, the vulnerable operation is reachable through the component’s normal input path. An actor can attempt to supply crafted data that flows to the affected code path without requiring special physical proximity.",
        "_provenance": {
          "origin": "fallback",
          "confidence": "medium"
        },
        "_evidence": {
          "desc_len": 402,
          "ref_hint": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
          "desc_excerpt": "picklescan before 0.0.21 does not treat 'pip' as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or G"
        }
      },
      "Attack_Complexity": {
        "Attack_Complexity_Reasoning": "No unusual timing or environment constraints are implied beyond providing inputs that reach the vulnerable code. Exploitation relies on typical parsing and handling of supplied data.",
        "_provenance": {
          "origin": "fallback",
          "confidence": "medium"
        },
        "_evidence": {
          "desc_len": 402,
          "ref_hint": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
          "desc_excerpt": "picklescan before 0.0.21 does not treat 'pip' as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or G"
        }
      },
      "Privileges_Required": {
        "Privileges_Required_Reasoning": "Access requirements follow the interface exposure described. If the operation sits behind authentication, an account with ordinary permissions is needed to invoke the flow.",
        "_provenance": {
          "origin": "fallback",
          "confidence": "medium"
        },
        "_evidence": {
          "desc_len": 402,
          "ref_hint": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
          "desc_excerpt": "picklescan before 0.0.21 does not treat 'pip' as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or G"
        }
      },
      "User_Interaction": {
        "User_Interaction_Reasoning": "Triggering appears to be at the actor’s will once the interface is reachable; no additional human interaction is implied unless a second party must handle content.",
        "_provenance": {
          "origin": "fallback",
          "confidence": "medium"
        },
        "_evidence": {
          "desc_len": 402,
          "ref_hint": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
          "desc_excerpt": "picklescan before 0.0.21 does not treat 'pip' as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or G"
        }
      },
      "Scope": {
        "Scope_Reasoning": "Effects remain within the component’s authority unless the vulnerable action influences a distinct backend or security boundary, which would extend impact beyond the immediate module.",
        "_provenance": {
          "origin": "fallback",
          "confidence": "medium"
        },
        "_evidence": {
          "desc_len": 402,
          "ref_hint": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
          "desc_excerpt": "picklescan before 0.0.21 does not treat 'pip' as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or G"
        }
      },
      "Confidentiality_Impact": {
        "Confidentiality_Impact_Reasoning": "Information disclosure is plausible if the operation reveals or returns data not intended for the requester, depending on how the system handles and exposes results.",
        "_provenance": {
          "origin": "fallback",
          "confidence": "medium"
        },
        "_evidence": {
          "desc_len": 402,
          "ref_hint": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
          "desc_excerpt": "picklescan before 0.0.21 does not treat 'pip' as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or G"
        }
      },
      "Integrity_Impact": {
        "Integrity_Impact_Reasoning": "Data tampering is possible if the vulnerable behavior allows unintended modification of stored content or state; otherwise integrity effects are not presumed.",
        "_provenance": {
          "origin": "fallback",
          "confidence": "medium"
        },
        "_evidence": {
          "desc_len": 402,
          "ref_hint": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
          "desc_excerpt": "picklescan before 0.0.21 does not treat 'pip' as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or G"
        }
      },
      "Availability_Impact": {
        "Availability_Impact_Reasoning": "Repeated triggering or expensive code paths could degrade throughput or lead to service disruption through resource exhaustion.",
        "_provenance": {
          "origin": "fallback",
          "confidence": "medium"
        },
        "_evidence": {
          "desc_len": 402,
          "ref_hint": "https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716",
          "desc_excerpt": "picklescan before 0.0.21 does not treat 'pip' as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or G"
        }
      },
      "_summary_quality": {
        "completed_metrics": 8,
        "fallback_metrics": 8,
        "model_metrics": 0,
        "web_supported": true,
        "desc_len": 402,
        "gate_fail_reasons": [],
        "note": "labels stripped before gate"
      },
      "AI_Raw_Response": {
        "content": "Login to continue using",
        "timestamp": "2025-09-08 02:21:55",
        "note": "raw model output before cleaning (may include CVSS tokens)"
      }
    }
  },
  {
    "ref_link": "https://github.com/mmaitre314/picklescan/commit/78ce704227c51f070c0c5fb4b466d92c62a7aa3d",
    "ref_desc": "",
    "ref_summary": {
      "Attack_Vector": {
        "Attack_Vector_Reasoning": "The vulnerability can be exploited remotely by submitting a malicious Pickle model that invokes pip to install arbitrary packages. Since the model may be hosted or distributed through common channels such as GitHub or PyPI, the attacker does not need access or proximity to the target system. This makes the attack feasible over a or via shared files, increasing the exposure surface. The model could be scanned or loaded by a user or automated system, triggering the malicious behavior without requiring the attacker to be present on the victim’s machine.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 5783,
          "desc_len": 402
        }
      },
      "Attack_Complexity": {
        "Attack_Complexity_Reasoning": "The exploitation does not require any unusual conditions or advanced techniques. The attacker simply needs to craft a Pickle payload that calls pip.main() to install a malicious package. This is a straightforward use of Python’s serialization mechanism and does not depend on race conditions, timing issues, or environmental factors. The vulnerability arises from the scanner’s failure to treat pip as unsafe, so the attacker can rely on predictable behavior from the scanning tool. The complexity is because the attack leverages standard Python functionality and widely available infrastructure.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 5783,
          "desc_len": 402
        }
      },
      "Privileges_Required": {
        "Privileges_Required_Reasoning": "The attack assumes that the scanning process or the environment where the Pickle model is loaded has sufficient privileges to execute pip and install packages. This typically requires write access to the Python environment or the ability to install system-level dependencies. If the scanner runs with elevated privileges or in a context where pip can modify the environment, the attacker can achieve significant impact. However, if the scanner is sandboxed or runs with limited permissions, the attack may be constrained. Therefore, some level of privilege is necessary for full exploitation.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 5783,
          "desc_len": 402
        }
      },
      "User_Interaction": {
        "User_Interaction_Reasoning": "The attack relies on a user or automated system loading or scanning a malicious Pickle model. This constitutes a form of interaction, as the model must be processed by the vulnerable tool for the exploit to occur. The user does not need to perform any complex actions—simply scanning the model with picklescan is sufficient. This makes the interaction minimal but still , as the exploit cannot trigger without some form of engagement with the malicious file. The attacker depends on this interaction to bypass security checks and execute pip.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 5783,
          "desc_len": 402
        }
      },
      "Scope": {
        "Scope_Reasoning": "The vulnerability affects the picklescan tool, but its impact can extend beyond the tool itself. By allowing pip to install arbitrary packages, the attacker can compromise other components of the system, including the Python runtime, third-party libraries, or even system-level configurations. This means the security boundaries of the scanning tool are breached, and the effects propagate to other domains. The scope is therefore broadened, as the attacker’s actions can influence resources and processes outside the original context of the vulnerability.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 5783,
          "desc_len": 402
        }
      },
      "Confidentiality_Impact": {
        "Confidentiality_Impact_Reasoning": "Once a malicious package is installed via pip, it could include code that exfiltrates sensitive data, such as environment variables, credentials, or user files. The attacker gains the ability to execute arbitrary Python code, which can be used to read and transmit confidential information. The impact depends on what data is accessible from the compromised environment, but in many cases, Python applications have access to valuable assets. Therefore, the potential for data leakage is significant if the malicious package is designed to harvest information.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 5783,
          "desc_len": 402
        }
      },
      "Integrity_Impact": {
        "Integrity_Impact_Reasoning": "The attacker can compromise the integrity of the system by installing packages that modify application behavior, inject malicious logic, or tamper with existing code. Since pip can install from arbitrary sources, the attacker could replace trusted components with altered versions. This undermines the reliability of the system and can lead to unauthorized changes in data or execution flow. The ability to execute pip commands through Pickle deserialization gives the attacker control over what code is introduced, making integrity violations highly plausible.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 5783,
          "desc_len": 402
        }
      },
      "Availability_Impact": {
        "Availability_Impact_Reasoning": "By installing malicious packages, the attacker could introduce denial-of-service conditions, such as infinite loops, resource exhaustion, or crashes. Python packages can include post-install scripts or runtime behaviors that degrade system performance or render services unavailable. If the scanner or the environment where the model is processed is to operations, this could result in significant downtime. The attacker’s control over the package contents means they can tailor the payload to disrupt availability, making this a realistic consequence of successful exploitation.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 5783,
          "desc_len": 402
        }
      },
      "_summary_quality": {
        "completed_metrics": 8,
        "fallback_metrics": 0,
        "model_metrics": 8,
        "web_supported": true,
        "desc_len": 402,
        "gate_fail_reasons": [],
        "note": "labels stripped before gate"
      },
      "AI_Raw_Response": {
        "content": "```json\n{\n  \"Attack_Vector_Reasoning\": \"The vulnerability can be exploited remotely by submitting a malicious Pickle model that invokes pip to install arbitrary packages. Since the model may be hosted or distributed through common channels such as GitHub or PyPI, the attacker does not need physical access or proximity to the target system. This makes the attack feasible over a network or via shared files, increasing the exposure surface. The model could be scanned or loaded by a user or automated system, triggering the malicious behavior without requiring the attacker to be present on the victim’s machine.\",\n  \n  \"Attack_Complexity_Reasoning\": \"The exploitation does not require any unusual conditions or advanced techniques. The attacker simply needs to craft a Pickle payload that calls pip.main() to install a malicious package. This is a straightforward use of Python’s serialization mechanism and does not depend on race conditions, timing issues, or environmental factors. The vulnerability arises from the scanner’s failure to treat pip as unsafe, so the attacker can rely on predictable behavior from the scanning tool. The complexity is low because the attack leverages standard Python functionality and widely available infrastructure.\",\n  \n  \"Privileges_Required_Reasoning\": \"The attack assumes that the scanning process or the environment where the Pickle model is loaded has sufficient privileges to execute pip and install packages. This typically requires write access to the Python environment or the ability to install system-level dependencies. If the scanner runs with elevated privileges or in a context where pip can modify the environment, the attacker can achieve significant impact. However, if the scanner is sandboxed or runs with limited permissions, the attack may be constrained. Therefore, some level of privilege is necessary for full exploitation.\",\n  \n  \"User_Interaction_Reasoning\": \"The attack relies on a user or automated system loading or scanning a malicious Pickle model. This constitutes a form of interaction, as the model must be processed by the vulnerable tool for the exploit to occur. The user does not need to perform any complex actions—simply scanning the model with picklescan is sufficient. This makes the interaction minimal but still required, as the exploit cannot trigger without some form of engagement with the malicious file. The attacker depends on this interaction to bypass security checks and execute pip.\",\n  \n  \"Scope_Reasoning\": \"The vulnerability affects the picklescan tool, but its impact can extend beyond the tool itself. By allowing pip to install arbitrary packages, the attacker can compromise other components of the system, including the Python runtime, third-party libraries, or even system-level configurations. This means the security boundaries of the scanning tool are breached, and the effects propagate to other domains. The scope is therefore broadened, as the attacker’s actions can influence resources and processes outside the original context of the vulnerability.\",\n  \n  \"Confidentiality_Impact_Reasoning\": \"Once a malicious package is installed via pip, it could include code that exfiltrates sensitive data, such as environment variables, credentials, or user files. The attacker gains the ability to execute arbitrary Python code, which can be used to read and transmit confidential information. The impact depends on what data is accessible from the compromised environment, but in many cases, Python applications have access to valuable assets. Therefore, the potential for data leakage is significant if the malicious package is designed to harvest information.\",\n  \n  \"Integrity_Impact_Reasoning\": \"The attacker can compromise the integrity of the system by installing packages that modify application behavior, inject malicious logic, or tamper with existing code. Since pip can install from arbitrary sources, the attacker could replace trusted components with altered versions. This undermines the reliability of the system and can lead to unauthorized changes in data or execution flow. The ability to execute pip commands through Pickle deserialization gives the attacker control over what code is introduced, making integrity violations highly plausible.\",\n  \n  \"Availability_Impact_Reasoning\": \"By installing malicious packages, the attacker could introduce denial-of-service conditions, such as infinite loops, resource exhaustion, or crashes. Python packages can include post-install scripts or runtime behaviors that degrade system performance or render services unavailable. If the scanner or the environment where the model is processed is critical to operations, this could result in significant downtime. The attacker’s control over the package contents means they can tailor the payload to disrupt availability, making this a realistic consequence of successful exploitation.\"\n}\n```",
        "timestamp": "2025-09-08 02:22:19",
        "note": "raw model output before cleaning (may include CVSS tokens)"
      }
    }
  },
  {
    "ref_link": "https://github.com/mmaitre314/picklescan/security/advisories/GHSA-655q-fx9r-782v",
    "ref_desc": "",
    "ref_summary": {
      "Attack_Vector": {
        "Attack_Vector_Reasoning": "The vulnerability can be exploited remotely by distributing a malicious pickle file that invokes pip to install arbitrary packages. Since the attack relies on deserialization of a crafted file, it does not require access or internal presence. The attacker can host the malicious model on public platforms like GitHub or PyPI, making it accessible over the internet. This significantly broadens the exposure surface, as any system that downloads and scans the pickle file using an affected version of picklescan is potentially vulnerable.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 11451,
          "desc_len": 402
        }
      },
      "Attack_Complexity": {
        "Attack_Complexity_Reasoning": "The attack does not require any specialized conditions beyond crafting a pickle file that includes a call to pip.main(). This is a known deserialization technique using Python’s reduce method, and pip is a commonly available module in Python environments. The attacker does not need to bypass any additional security mechanisms or rely on race conditions. The simplicity of embedding a pip call in a pickle file and the lack of detection by picklescan prior to version 0.0.21 make this attack straightforward to execute.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 11451,
          "desc_len": 402
        }
      },
      "Privileges_Required": {
        "Privileges_Required_Reasoning": "The attacker does not need any privileges on the target system to exploit this vulnerability. The malicious pickle file can be executed during deserialization by any user running the scanning tool. Since pip is typically available in user-space Python environments, the attack can succeed without elevated permissions. The vulnerability lies in the scanning tool’s failure to flag pip as unsafe, not in any permission-based access control, which means even -privileged users can trigger the exploit if they deserialize the file.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 11451,
          "desc_len": 402
        }
      },
      "User_Interaction": {
        "User_Interaction_Reasoning": "Exploitation requires a user to scan or deserialize a malicious pickle file using picklescan. This means the user must take an action—such as running a scan or loading a model—that triggers the deserialization process. The vulnerability does not execute autonomously; it depends on user-initiated interaction with the file. This interaction is typical in machine learning workflows where models are loaded or validated, making it a plausible scenario but still dependent on user behavior.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 11451,
          "desc_len": 402
        }
      },
      "Scope": {
        "Scope_Reasoning": "The vulnerability affects the scanning tool’s ability to detect malicious content, but the impact extends beyond the tool itself. When exploited, it can lead to remote code execution on the host system where the scan occurs, potentially affecting other components or systems. This means the security boundaries of the scanning tool are breached, and the consequences propagate to the broader environment. The malicious package installed via pip can execute arbitrary code, altering the behavior of unrelated applications or services.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 11451,
          "desc_len": 402
        }
      },
      "Confidentiality_Impact": {
        "Confidentiality_Impact_Reasoning": "While the vulnerability itself does not directly target data confidentiality, the ability to execute arbitrary code via a malicious package opens the door to secondary attacks. An attacker could install a package that exfiltrates sensitive data, such as credentials or personal information, from the host system. The initial exploit vector is generic, but the payload delivered through pip can be tailored to compromise confidentiality depending on the attacker’s intent and the system’s configuration.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 11451,
          "desc_len": 402
        }
      },
      "Integrity_Impact": {
        "Integrity_Impact_Reasoning": "The vulnerability allows an attacker to install arbitrary packages, which can modify system files, inject malicious code, or alter application behavior. This directly affects the integrity of the host system. For example, a malicious package could tamper with configuration files, override trusted libraries, or introduce backdoors. Since the scanning tool fails to detect the unsafe use of pip, it provides a false sense of security, enabling integrity violations without alerting the user.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 11451,
          "desc_len": 402
        }
      },
      "Availability_Impact": {
        "Availability_Impact_Reasoning": "The exploit can lead to remote code execution, and depending on the payload, it may impact system availability. An attacker could install a package that consumes excessive resources, deletes files, or initiates denial-of-service conditions. Although the vulnerability does not inherently cause a crash or halt, the arbitrary nature of the installed package means availability can be compromised if the attacker chooses to deploy disruptive code. The scanning tool’s failure to detect this risk contributes to the potential for downtime.",
        "_provenance": {
          "origin": "model",
          "confidence": "medium"
        },
        "_evidence": {
          "web_supported": true,
          "web_status": 200,
          "web_len": 11451,
          "desc_len": 402
        }
      },
      "_summary_quality": {
        "completed_metrics": 8,
        "fallback_metrics": 0,
        "model_metrics": 8,
        "web_supported": true,
        "desc_len": 402,
        "gate_fail_reasons": [],
        "note": "labels stripped before gate"
      },
      "AI_Raw_Response": {
        "content": "{\n  \"Attack_Vector_Reasoning\": \"The vulnerability can be exploited remotely by distributing a malicious pickle file that invokes pip to install arbitrary packages. Since the attack relies on deserialization of a crafted file, it does not require physical access or internal network presence. The attacker can host the malicious model on public platforms like GitHub or PyPI, making it accessible over the internet. This significantly broadens the exposure surface, as any system that downloads and scans the pickle file using an affected version of picklescan is potentially vulnerable.\",\n  \n  \"Attack_Complexity_Reasoning\": \"The attack does not require any specialized conditions beyond crafting a pickle file that includes a call to pip.main(). This is a known deserialization technique using Python’s reduce method, and pip is a commonly available module in Python environments. The attacker does not need to bypass any additional security mechanisms or rely on race conditions. The simplicity of embedding a pip call in a pickle file and the lack of detection by picklescan prior to version 0.0.21 make this attack straightforward to execute.\",\n  \n  \"Privileges_Required_Reasoning\": \"The attacker does not need any privileges on the target system to exploit this vulnerability. The malicious pickle file can be executed during deserialization by any user running the scanning tool. Since pip is typically available in user-space Python environments, the attack can succeed without elevated permissions. The vulnerability lies in the scanning tool’s failure to flag pip as unsafe, not in any permission-based access control, which means even low-privileged users can trigger the exploit if they deserialize the file.\",\n  \n  \"User_Interaction_Reasoning\": \"Exploitation requires a user to scan or deserialize a malicious pickle file using picklescan. This means the user must take an action—such as running a scan or loading a model—that triggers the deserialization process. The vulnerability does not execute autonomously; it depends on user-initiated interaction with the file. This interaction is typical in machine learning workflows where models are loaded or validated, making it a plausible scenario but still dependent on user behavior.\",\n  \n  \"Scope_Reasoning\": \"The vulnerability affects the scanning tool’s ability to detect malicious content, but the impact extends beyond the tool itself. When exploited, it can lead to remote code execution on the host system where the scan occurs, potentially affecting other components or systems. This means the security boundaries of the scanning tool are breached, and the consequences propagate to the broader environment. The malicious package installed via pip can execute arbitrary code, altering the behavior of unrelated applications or services.\",\n  \n  \"Confidentiality_Impact_Reasoning\": \"While the vulnerability itself does not directly target data confidentiality, the ability to execute arbitrary code via a malicious package opens the door to secondary attacks. An attacker could install a package that exfiltrates sensitive data, such as credentials or personal information, from the host system. The initial exploit vector is generic, but the payload delivered through pip can be tailored to compromise confidentiality depending on the attacker’s intent and the system’s configuration.\",\n  \n  \"Integrity_Impact_Reasoning\": \"The vulnerability allows an attacker to install arbitrary packages, which can modify system files, inject malicious code, or alter application behavior. This directly affects the integrity of the host system. For example, a malicious package could tamper with configuration files, override trusted libraries, or introduce backdoors. Since the scanning tool fails to detect the unsafe use of pip, it provides a false sense of security, enabling integrity violations without alerting the user.\",\n  \n  \"Availability_Impact_Reasoning\": \"The exploit can lead to remote code execution, and depending on the payload, it may impact system availability. An attacker could install a package that consumes excessive resources, deletes critical files, or initiates denial-of-service conditions. Although the vulnerability does not inherently cause a crash or halt, the arbitrary nature of the installed package means availability can be compromised if the attacker chooses to deploy disruptive code. The scanning tool’s failure to detect this risk contributes to the potential for downtime.\"\n}",
        "timestamp": "2025-09-08 02:22:43",
        "note": "raw model output before cleaning (may include CVSS tokens)"
      }
    }
  }
]